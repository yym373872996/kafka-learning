# 创建与 kafka 集群建立连接的地址集合
bootstrap.servers=localhost:9092,localhost:9093,localhost:9094
# key 的序列化方式，必须指定，无默认值
#key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
# value 的序列化方式，必须指定，无默认值
#value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
# 标识该消费者程序属于消费者组的唯一字符串，默认为空字符串
group.id=0
# 在使用 kafka 消费者组时，消费者协调器设置的心跳时间，默认为 3 s
#heartbeat.interval.ms=3000
# 服务器返回的每个分区的最大数据量，默认为 1 MB
#max.partition.fetch.bytes=1048576
# 使用 kafka 消费者组管理时，设置消费者程序的超时时间，默认为 10 s
#session.timeout.ms=10000
# 重置消费者偏移量值，默认为 latest
# earliest 从头开始消费
# latest 从最新的消息记录开始消费
# none 从已提交的偏移量开始消费
# anything else 向消费者抛出异常
#auto.offset.reset=latest
# 在这个配置所指定的毫秒数之后关闭空闲的连接， 默认为 9 min
#connections.max.idle.ms=540000
# 是否设置自动提交偏移量，默认为 true
# true 开启自动提交
# false 手动提交
enable.auto.commit=true
# 自动提交的时间间隔
auto.commit.intervals.ms=1000
# 内部主题的记录不被消费者程序访问，默认为 true
#exclude.internal.topics=true
# 服务器为获取请求返回的最小数据量，默认为 1 B
#fetch.min.btyes=1
# 服务器为获取请求所需的最大数据量，默认为 50 MB
#fetch.max.btyes=52428800
# 使用消费者组读取数据时的最大的延时时间，默认为 5 min
#max.poll.interval.ms=300000
# 单次读取数据所返回的最大记录数，默认为 500 条
#max.poll.records=500
# 设置缓冲区接收数据的字节大小，默认为 64 KB
#receive.buffer.bytes=65536
# 客户端等待请求响应的最大时间，默认为 305 s
#request.timeout.ms=305000
# 安全认证的文件路径，默认为 null
#java.security.auth.login.config=null
# 与 kafka 代理节点通信的协议，可选值：PLAINTEXT、SSL、SASL_PLAINTEXT、SASL_SSL，默认为 PLAINTEXT
#security.protocol=PLAINTEXT
# 用于客户端连接的 SASL 机制，默认为 GSSAPI
#sasl.mechanism=GSSAPI
# 发送数据时，设置缓冲区的大小，默认为 128 KB
#send.buffer.bytes=131072